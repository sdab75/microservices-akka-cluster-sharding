akka {
    #log-dead-letters = 10
    #log-dead-letters-during-shutdown = off
    #loglevel = "DEBUG"
    # Log the complete configuration at INFO level when the actor system is started.
    # This is useful when you are uncertain of what configuration is used.
    #log-config-on-start = on
    actor {
        provider = "akka.cluster.ClusterActorRefProvider"
        debug {
            # enable DEBUG logging of actor lifecycle changes
            #lifecycle = on
        }
    }
    remote {
        #log-remote-lifecycle-events = on
        # if off then they are not logged
        #log-sent-messages = on
        # if off then they are not logged
        #log-received-messages = on
        netty.tcp {
            hostname = "127.0.0.1"
            port = 2550
        }
    }
    cluster {
        seed-nodes = [
            "akka.tcp://ClusterSystem@127.0.0.1:2550",
            "akka.tcp://ClusterSystem@127.0.0.1:2551"]
        roles = [ "one"]
        auto-down-unreachable-after = 10s
    }
    persistence {
        journal {
            plugin = "cassandra-journal"
            #plugin = "akka.persistence.cassandra.journal.CassandraJournal"
            # Comma-separated list of contact points in the cluster
            #cassandra-journal.contact-points = ["ffx-gnt-dkr2"]
            #cassandra-journal.keyspace= "sridhar"
        }

        snapshot-store {
            plugin = "cassandra-snapshot-store"
            #plugin = "akka.persistence.snapshot-store.local"
            # Comma-separated list of contact points in the cluster
            #cassandra-journal.contact-points = ["ffx-gnt-dkr2"]
            #cassandra-journal.keyspace= "sridhar"
        }
    }
    akka.extensions = ["akka.cluster.client.ClusterClientReceptionist"]
}
#cassandra-journal.contact-points = ["ffx-gnt-dkr1:9042"]
#cassandra-snapshot-store.contact-points = ["ffx-gnt-dkr1:9042"]
#cassandra-journal.contact-points = ["172.16.10.25:9042"]
#cassandra-snapshot-store.contact-points = ["172.16.10.25:9042"]
cassandra-journal.contact-points = ["localhost:9042"]
cassandra-snapshot-store.contact-points = ["localhost:9042"]
akka.extensions = ["akka.cluster.client.ClusterClientReceptionist"]
akka.actor.default-mailbox.stash-capacity=10000

# Settings for the ClusterShardingExtension
akka.cluster.sharding {

    # The extension creates a top level actor with this name in top level system scope,
    # e.g. '/system/sharding'
    guardian-name = sharding

    # Specifies that entities runs on cluster nodes with a specific role.
    # If the role is not specified (or empty) all nodes in the cluster are used.
    role = ""

    # When this is set to 'on' the active entity actors will automatically be restarted
    # upon Shard restart. i.e. if the Shard is started on a different ShardRegion
    # due to rebalance or crash.
    remember-entities = on

    # If the coordinator can't store state changes it will be stopped
    # and started again after this duration, with an exponential back-off
    # of up to 5 times this duration.
    coordinator-failure-backoff = 5 s

    # The ShardRegion retries registration and shard location requests to the
    # ShardCoordinator with this interval if it does not reply.
    retry-interval = 2 s

    # Maximum number of messages that are buffered by a ShardRegion actor.
    buffer-size = 100000

    # Timeout of the shard rebalancing process.
    handoff-timeout = 60 s

    # Time given to a region to acknowledge it's hosting a shard.
    shard-start-timeout = 10 s

    # If the shard is remembering entities and can't store state changes
    # will be stopped and then started again after this duration. Any messages
    # sent to an affected entity may be lost in this process.
    shard-failure-backoff = 10 s

    # If the shard is remembering entities and an entity stops itself without
    # using passivate. The entity will be restarted after this duration or when
    # the next message for it is received, which ever occurs first.
    entity-restart-backoff = 10 s

    # Rebalance check is performed periodically with this interval.
    rebalance-interval = 10 s

    # Absolute path to the journal plugin configuration entity that is to be
    # used for the internal persistence of ClusterSharding. If not defined
    # the default journal plugin is used. Note that this is not related to
    # persistence used by the entity actors.
    journal-plugin-id = ""

    # Absolute path to the snapshot plugin configuration entity that is to be
    # used for the internal persistence of ClusterSharding. If not defined
    # the default snapshot plugin is used. Note that this is not related to
    # persistence used by the entity actors.
    snapshot-plugin-id = ""

    # Parameter which determines how the coordinator will be store a state
    # valid values either "persistence" or "ddata"
    # The "ddata" mode is experimental, since it depends on the experimental
    # module akka-distributed-data-experimental.
    state-store-mode = "persistence"

    # The shard saves persistent snapshots after this number of persistent
    # events. Snapshots are used to reduce recovery times.
    snapshot-after = 1000

    # Setting for the default shard allocation strategy
    least-shard-allocation-strategy {
        # Threshold of how large the difference between most and least number of
        # allocated shards must be to begin the rebalancing.
        rebalance-threshold = 10

        # The number of ongoing rebalancing processes is limited to this number.
        max-simultaneous-rebalance = 3
    }

    # Timeout of waiting the initial distributed state (an initial state will be queried again if the timeout happened)
    # works only for state-store-mode = "ddata"
    waiting-for-state-timeout = 5 s

    # Timeout of waiting for update the distributed state (update will be retried if the timeout happened)
    # works only for state-store-mode = "ddata"
    updating-state-timeout = 5 s

    # Settings for the coordinator singleton. Same layout as akka.cluster.singleton.
    coordinator-singleton = ${akka.cluster.singleton}

    # The id of the dispatcher to use for ClusterSharding actors.
    # If not specified default dispatcher is used.
    # If specified you need to define the settings of the actual dispatcher.
    # This dispatcher for the entity actors is defined by the user provided
    # Props, i.e. this dispatcher is not used for the entity actors.
    use-dispatcher = ""
}